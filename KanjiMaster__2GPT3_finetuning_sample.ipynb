{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb_D8Dxf1NAa"
      },
      "source": [
        "GPT-3で再学習（fine-tuning）を行うサンプルコードです"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeFXH04PX6IB"
      },
      "source": [
        "### **google driveをマウントする（Mount google drive）**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuHckGS3BwRn",
        "outputId": "3962dc74-9fb9-4f1e-f17c-dbda3ecb24a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g6FxlBPYiK2"
      },
      "source": [
        "### **openaiをインストール（Install openai）**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRtKm_WwBhz5",
        "outputId": "dca62314-48bb-4058-c37a-3287631c480b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai==0.25.0\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.9-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai==0.25.0) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai==0.25.0) (3.0.10)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai==0.25.0) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai==0.25.0) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai==0.25.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai==0.25.0) (1.21.6)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.230105-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.14.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai==0.25.0) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai==0.25.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai==0.25.0) (2022.7)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.1.0-py3-none-any.whl (4.8 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.25.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.25.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.25.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.25.0) (4.0.0)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: openai, pathtools\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=747de99dbb38283710edae5264ecc7f3d76aba222c3b23221e1436b88a755e4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c45d11286952dc8eca21d20daa9dbde3c313fc5c78a65780e1b7ea44b25cba7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built openai pathtools\n",
            "Installing collected packages: types-pytz, pathtools, urllib3, smmap, setproctitle, pandas-stubs, docker-pycreds, sentry-sdk, gitdb, openai, GitPython, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed GitPython-3.1.30 docker-pycreds-0.4.0 gitdb-4.0.10 openai-0.25.0 pandas-stubs-1.5.2.230105 pathtools-0.1.2 sentry-sdk-1.14.0 setproctitle-1.3.2 smmap-5.0.0 types-pytz-2022.7.1.0 urllib3-1.26.14 wandb-0.13.9\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.25.0 wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhF1ph54TGfb"
      },
      "source": [
        "### **OpenAIで取得したAPI Keyやトレーニングデータのファイル名を設定**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2gkT9ujTOHK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import codecs\n",
        "\n",
        "openai.api_key = \"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\" # 自分で取得したAPI Keyに変更する\n",
        "os.environ['OPENAI_API_KEY'] = openai.api_key\n",
        "train_name = \"kanjimaster1\"    # CSVファイル名の.csv以前の文字列\n",
        "os.environ['TRAIN_NAME']  = train_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efFWpTGCZC60"
      },
      "source": [
        "### **トレーニングデータをJSONLファイルに変換**  \n",
        "- トレーニングデータの詳しい作り方は https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset を参照  \n",
        "(For detailed instructions on how to create training data, see https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0qK1nmVCEDA",
        "outputId": "75e2ed0a-7589-471b-dc33-899e6ba6fa92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file appears to be in a .JSON format. Your file will be converted to JSONL format\n",
            "- Your file contains 250 prompt-completion pairs\n",
            "- All prompts end with suffix ` -> `\n",
            "- All completions end with suffix `END`\n",
            "  WARNING: Some of your completions contain the suffix `END` more than once. We suggest that you review your completions and add a unique ending\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `JSON` will be converted to `JSONL`\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: y\n",
            "\n",
            "Wrote modified file to `/content/drive/MyDrive/kanjimaster1_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/drive/MyDrive/kanjimaster1_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` -> ` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"END\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 5.88 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "# CSVファイルの読み込みと変換\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/\" + train_name + \".csv\", encoding=\"utf8\", dtype=str) # 文字コードUTF-8の場合は、encoding=\"utf8\"に変更\n",
        "\n",
        "# JSONファイルへ書き出し\n",
        "f = codecs.open(\"/content/drive/MyDrive/\" + train_name + \".json\", 'w', \"utf8\")\n",
        "f.write(\"[\\n\")\n",
        "for index, row in df.iterrows():\n",
        "  f.write('{\"prompt\":\"' + str(row[0]).replace(\"\\n\", \"\\\\n\").replace(\"\\\"\", \"\\\\\\\"\") + ' -> \", \"completion\":\"' + str(row[1]).replace(\"\\n\", \"\\\\n\").replace(\"\\\"\", \"\\\\\\\"\") + 'END\"}')\n",
        "  if index < len(df)-1:\n",
        "    f.write(\",\")\n",
        "  f.write(\"\\n\")\n",
        "f.write(\"]\")\n",
        "f.close()\n",
        "\n",
        "# JSONLファイルへ変換\n",
        "! openai tools fine_tunes.prepare_data -f \"/content/drive/MyDrive/${TRAIN_NAME}.json\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iTAqQRKbh7S"
      },
      "source": [
        "### **ファインチューニングを始める**  \n",
        "- APIキーは https://beta.openai.com/account/api-keys で確認できる  \n",
        "(The API key can be found at https://beta.openai.com/account/api-keys)\n",
        "- ファインチューニングの詳しいことは https://beta.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model を参照  \n",
        "(For more information on fine tuning, see https://beta.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVk5nrngDoDW",
        "outputId": "6cb5b7ee-fd7c-414c-ed5a-a915baf159cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rUpload progress:   0% 0.00/259k [00:00<?, ?it/s]\rUpload progress: 100% 259k/259k [00:00<00:00, 340Mit/s]\n",
            "Uploaded file from /content/drive/MyDrive/kanjimaster1_prepared.jsonl: file-RcAQ5C8c7oHBKCuHQgQ2f2r9\n",
            "Created fine-tune: ft-NjbnvklOe97hEAPqPyDK6Lyu\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-01-31 00:47:46] Created fine-tune: ft-NjbnvklOe97hEAPqPyDK6Lyu\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-NjbnvklOe97hEAPqPyDK6Lyu\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! openai api fine_tunes.create -t \"/content/drive/MyDrive/${TRAIN_NAME}_prepared.jsonl\" --batch_size 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfAdMHhYVKfc",
        "outputId": "f27526ec-c71a-4219-8470-ef44434a7191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-31 00:47:46] Created fine-tune: ft-NjbnvklOe97hEAPqPyDK6Lyu\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-NjbnvklOe97hEAPqPyDK6Lyu\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.follow -i ft-NjbnvklOe97hEAPqPyDK6Lyu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIkX5KmyjftB"
      },
      "source": [
        "### **ファインチューニングしたモデルをコマンドで実行する**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDpqZ77YcuK4",
        "outputId": "658a77ea-aa2c-4c96-8d50-80e325e419f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one _________ (bottom radical)\n",
            "PK\n",
            "You can use it to mean \"bottom\" or \"dwarf,\" but it's more often used to mean \"one,\" like 'one person,' or 'one time.'\n",
            "Used In\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
            "I don't know the kanji, but I think it basically means, \"one time.\"\n",
            "Used In\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
            "\n",
            "'one' - you don't need to know the kanji for this one.\n",
            "\n",
            "Lookalikes\n"
          ]
        }
      ],
      "source": [
        "# 下記のcurie:ft-nagoya-institute-of-technology-2022-05-19-20-11-26 を自分で作ったモデル名に変更し、判定する語句も適当に減脳してみる\n",
        "! openai api completions.create -m curie:ft-personal-2023-01-30-08-25-49 -p \"one \" -M 500 -t 0.7 --stop END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k03K1xK-fuJJ"
      },
      "source": [
        "### **ファインチューニングしたモデルをpythonで実行する (Run the model saved in python.)**  \n",
        "- 詳しくは https://beta.openai.com/docs/guides/fine-tuning/use-a-fine-tuned-model を参照  \n",
        "(For more information, see https://beta.openai.com/docs/guides/fine-tuning/use-a-fine-tuned-model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MVtVvjZtNiJ",
        "outputId": "cff04b75-ca4c-446c-8079-995fd0c748fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-the-fold text in the Washington Post more on Inauguration Day 2017 than for Donald Trump’s inauguration three months earlier. Apparently. Plus, beyond the novelty of it all, is there a temerity in only putting this in the upper left-hand quadrant of your newspaper? I presume you saved this for a spot above the fold because it encapsulates so much of what’s gone wrong with politics and media in the United States that year. And maybe, by putting it above the fold, you demonstrate for those of us who are still catching up that you know how to cover the Trump phenomenon as a writer and that you are not in this just as a journalist, that is, attached to the same wound but trying to help slough it off a little with essential blood. Anyway, now that you mentioned it, I find it stuck out. There are many things stuck out in it. If you read them out loud they sound like repeated tacky hip-hop lyrics that are repeated over and over and over again.\n",
            "-Sometimes, the phrase comes at the end of the following sentence: \"As Mr. Schroeder now knows, an upper left-hand quadrant hit to the story is sometimes what shakes the world.\" But he needs to hit the power button on his iPhone because his scooter is about to go down that steep kind of curving hill if he's not wearing hand-guards.\n",
            "-\"Why did Donald Trump do this at once with so much urgency? He knew that the moon was in an upper left-hand quadrant, and he made a date to have a date with it. I think he is famous for the Chinese tradition of \"hongbao,\" like you are throwing them in the air and then mumbling these inscrutable syllables over and over again.\"\n",
            "- \"Like a sloth or a walrus or lying on a sofa.\"\n",
            "- \"The media like to say that 'above the fold' means the first 25 words of stories, but some comics said 'above the fold' means the first occurence in the alphabet. But that's clearly false because I and the wildlife appreciate what a good job the upper right-hand quadrant did by occurance, so this is not that.\"\n",
            "- \"An upper lower-left quadrant dick or mouth.\" The former is where I am currently parked, while the later seems to be limberly held by George Extremely Contemporary New\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "test_prompt = \"above\"\n",
        "model_name = \"curie:ft-personal-2023-01-30-08-25-49\" # 自分で作ったモデル名に変更する\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model = model_name,\n",
        "    prompt = test_prompt,\n",
        "    max_tokens = 500,\n",
        "    stop = [\"END\"],\n",
        "    )\n",
        "\n",
        "#result = re.search('-> (.+?)end', response['choices'][0]['text'])\n",
        "#if result:\n",
        "  #print(result.group(1))\n",
        "print(response['choices'][0]['text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3TMLao6CHPu"
      },
      "source": [
        "### **否定形テスト**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKRLDLJUA8FW",
        "outputId": "093977a8-b6ce-48f4-c9b7-ae65882fb8f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one _____ EMPI (same-color radical)\n",
            "Onyomi\n",
            "SEI\t\n",
            "Mnemonic\n",
            "There's a ___ on the EYE of your LEFT eye and a ___in the same-color spot on your RIGHT one!\n",
            "\n",
            "Kunyomi\n",
            "__*_\tone person's idea or one type of q-tip's tip is the same color as another person's\n",
            "_______\n",
            "__*__\tit's the same stuff, ('every time____in 4 kanji')\n",
            "_____\n",
            "Jukugo\n",
            "________\t\n",
            "unfair treatment _____\n",
            "_ (one) + _ (protest) = ___ (unfair treatment)\n",
            "\n",
            "Lookalikes\n",
            "Meaning\tHint\tRadical\n",
            "_\tone person's idea or one type of q-tip's tip is the same color as another person's\tBOTTOM CROTCH\t_\n",
            "_\tswirl\tSPINE-MUFFIN\t_\n",
            "My crazy, swirl-muffin has a guy's face, FACE-DOWN in the center, and he's got MOUTH and EYES at the bottom.ENDERFINISHING.ENDERFINISHERS AND NOSEbecause life is MCRUSH: we got a CRUNCHENDERTER on the bottom,COMES IN FACE-UP, and THENLIFE sneaks up ON US AND CARESS US\n",
            "\n",
            "Used In\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
            "Synonyms\n",
            "unfair treatment\n",
            "_______    ______   ENDER ELITE'S NECESSITY\n",
            "_    __    __    _   _______ ___    _ ___    _ ____    ___ ENDER LIBRARY\n",
            "is usually used in the following contexts:\n",
            "\n",
            "____ ___ ____ ____ ____\n",
            "connected things, like if job A is unfair, having a job B (which also crummy) might be good enough, since people normally get better paid the more they make\n",
            "___________    ___ _   \n",
            "of one quality, type\n",
            "ENDER    _\n",
            "the END of something, like the ENDER of your patience.ENDERVERSEENDER\n",
            "Enders\n",
            "ENDER is kind of like \"nodes\n",
            "two MANE\n",
            "(top radical)\n",
            "PK\n",
            "Although you think it looks like (left radical), it's not!\n",
            "Used In\n",
            "_ _ _ _\n",
            "Synonyms\n",
            "pair of MANES\n",
            "--- _ _ _ _ _ __ ___ ____ __END\n",
            "_ xxx / ___END\n",
            "__END\n",
            "END Of Series\n",
            "Lookalikes\n",
            "ENDING\n",
            "ENDINGERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDERENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDEND\n",
            "three  _ three\n",
            "(leftbottom) + _ (palm / hand)\n",
            "_____\n",
            "10 strokes\n",
            "Onyomi\n",
            "RO\t\n",
            "Mnemonic\n",
            "There are three palms on the left side of the mannequin. I don't know if they are holding daggers, but they look wicked.\n",
            "\n",
            "Kunyomi\n",
            "___\tthree things\n",
            "_____\n",
            "Jukugo\n",
            "_____\t\n",
            "the number 3 _____ KANA\n",
            "\n",
            "_____ __\t\n",
            "the number 3. _____ strict_form\n",
            "_ (three) + _ (person) = __ (the number 3.)\n",
            "\n",
            "________\t\n",
            "three\n",
            "\n",
            "\n",
            "just three things : a song, a show, or a stand-up comedian\n",
            "\n",
            "____\t\n",
            "tomorrow _____\n",
            "_ (three) + _ (sun, day) = __ (tomorrow!)\n",
            "\n",
            "_______\t\n",
            "January _____\n",
            "_ (three) + _ (moon) + _ (climate) = ___ (January)\n",
            "\n",
            "Lookalikes\n",
            "Meaning\tHint\tRadical\n",
            "_\tthree\tTREP\t_\n",
            "_\twithout defects\tMOAT CROWN\t_\n",
            "Three, although you can count the TPH CROWNS if you want. The MOOAT CROWN has holes in the top, because of course it does.\n",
            "Three - but without the number.\n",
            "\n",
            "Used In\n",
            "_\n",
            "Synonyms\n",
            "tomorrow\n",
            "________\t\n",
            "Thursday\n",
            "_ ____\t\n",
            "January\n",
            "_ ____\t\n",
            "third year\n",
            "_ ____\t\n",
            "three\n",
            "_ ____\t\n",
            "three score and ten\n",
            "_ ____\t\n",
            "third party\n",
            "_____\t\n",
            "big, vast, enormous\n",
            "__ ____\t\n",
            "many, much, a lot\n",
            "___ _____\t\n",
            "March _____ _ ____ __ _____\t\n",
            "Meteorology\n",
            "__ ____\t\n",
            "three is enough\n",
            "_ ____ _ __ ____\t\n",
            "three a day, for a month\n",
            "__ ____\t\n",
            "three, although you can count it if you want.\n",
            "___ _____\t\n",
            "February Rosa\n",
            "__ ____\t\n",
            "third party\n",
            "__ ____ _ ____ _______\t\n",
            "three in a row. IIIt's the third time.\n",
            "__ ____ _____ _ ____ ____\n",
            "Three CROWNS.\n",
            "However - you can count the TPH CROWVs if you want!\n",
            "\n",
            "Lookalikes\n",
            "Me\n",
            "above  left before\n",
            " (top radical)\n",
            "PK\n",
            "All of the radicals meaning \"preschool \"-_______END Walt RECENTER\n",
            "Used In\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
            "END WALT _______\n",
            "END means 'cul-de-sac,' 'nook,' or 'stoop.'\n",
            "Used In\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
            "the 'unkuso'\n",
            "Used In\n",
            "_ _ _ _ _ _ ____ _ _ _ _ _ _\n",
            "the 2 main words used to describe your sexual preferences, sex-u-al vor-e-ty:\"gay,\" and \"straights.\"\n",
            "Used In\n",
            "_ _ _ _ _ _ _ _ _ _ _ _\n",
            "A sex act.END\n",
            "\n",
            "_ _ _ _Pun\n",
            "Used In\n",
            "_ _ _ _ _____ _ _\n",
            "The thing that parents sing to their kids to make them go to sleep.END\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _____ _ _\n",
            "Shit.ENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDEND\n",
            "\n",
            "Used In\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _____ _ _ _ _ __ _ _ _ _ _ _\n",
            "(A) butt sex\n",
            "_ _ ____ ____ ____ ____\n",
            "bottom\n",
            "END\n",
            "_ _ _____ ____ ____\n",
            "domestic\n",
            "ENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDENDEND\n",
            "goodwaytime Day_07\n",
            "Ok gurl you're looking damn good damn good there. Day_08\n",
            "Somebody call 18 Wheeler a Muppet, it's head looks like a giant muppet. Day_09\n",
            "Man, don't you frown on this day or your soul stop moving. Or your grimace stagnates or something.\n",
            "Or do something stupid and horribly ventriloquistic. Depends who the target audience is, probably.\n",
            "Whatever! I'm done with that.\n",
            "Scene_01\n",
            "Fade in on FUNKO'S Twitter\n",
            "FUNKO. I know nothing about you, your insufferable essence that carries through the medium of stuffed toys and sugar cereal, but I do know you're an annoying dickhead. But at least you don't try and hum the National Anthem and shit! We both just want what's best for the kids ffs.\n",
            "I didn't get this. I thought it was like a promotional poster for Dungeons and Dragons. On that note I hereby pronounce your themed merch and this scene from your telly show real as fuck\n",
            "Skyrim\n",
            "Omg you always get shit on you like your horse is always what is that there can't be more than three 60s in the game and it's just more dragons.\n",
            "-Silence\n",
            "I tried looking it up but apparently it's a space pixel artist from the Usta Erzes, but he's the most prolific of his class.\n",
            "He lives here too, somewhere in Orlando\n",
            "So much leeeeef Sir Space Leeeef. LEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEF\n",
            "What's funny is The Witness never gave me that mood. I gave up very early.\n",
            "Scene_02\n",
            "Fade in on my JNCO shirt I found at the thrift store.\n",
            "That's a glory outfit right there!\n",
            "Did they take it off the terror suspects or what?\n",
            "You can see the dog tags hanging on that joker.\n",
            "Scene_03\n",
            "Bitch put the lights out!\n",
            "Ahhhhhhhhhhhhh! BITCH PUT THE LIGHTS OUT OR I WILL SMOKE THEM MYSELF\n",
            "And if I had the mettle, I would.\n",
            "Scene_04\n",
            "Not so great now am I? (In a Korean accent)\n",
            "I was late for work because I was in the bathroom OH DAMN IT\n",
            "Oh yeah! Balls!\n"
          ]
        }
      ],
      "source": [
        "! openai api completions.create -m curie:ft-personal-2023-01-30-08-25-49  -p \"one \" -M 500 ; echo\n",
        "! openai api completions.create -m curie:ft-personal-2023-01-30-08-25-49 -p \"two \" -M 500; echo\n",
        "\n",
        "! openai api completions.create -m curie:ft-personal-2023-01-30-08-25-49 -p \"three \" -M 500; echo\n",
        "! openai api completions.create -m curie:ft-personal-2023-01-30-08-25-49 -p\"above \" -M 500; echo\n",
        "\n",
        "! openai api completions.create -m curie:ft-personal-2023-01-30-08-25-49 -p \"good\" -M 500; echo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm-KEuQ-yans"
      },
      "source": [
        "Prompt with GRadio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nl3hqMRyZxx",
        "outputId": "459289a9-467a-4afc-971e-4ded5c9ab319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.17.0-py3-none-any.whl (14.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio) (1.21.6)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (4.2.0)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio) (1.10.4)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.5-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from gradio) (4.4.0)\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio) (6.0)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.89.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio) (2.25.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio) (2022.11.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio) (3.2.2)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2022.7)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Collecting starlette==0.22.0\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from python-multipart->gradio) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.10.2)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.2.0->gradio) (3.11.0)\n",
            "Building wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=09f1bc117a0ef9b5b6810d5bcc2acaaf6f19b388f39474a1805ff428049a1edf\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=ee023f447f245f5e16f3c36b717f390d796212a8e61bf139d416160f03c83e71\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: rfc3986, pydub, ffmpy, websockets, uc-micro-py, sniffio, python-multipart, pycryptodome, orjson, mdurl, h11, aiofiles, uvicorn, markdown-it-py, linkify-it-py, anyio, starlette, mdit-py-plugins, httpcore, httpx, fastapi, gradio\n",
            "Successfully installed aiofiles-22.1.0 anyio-3.6.2 fastapi-0.89.1 ffmpy-0.3.0 gradio-3.17.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.5 pycryptodome-3.17 pydub-0.25.1 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.22.0 uc-micro-py-1.0.1 uvicorn-0.20.0 websockets-10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "LDrkxgJnzVC8",
        "outputId": "8b973573-06fe-40ec-b587-09d6ce3db475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7862, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "def greet(test_prompt):\n",
        "  \n",
        "  model_name = \"curie:ft-personal-2023-01-30-08-25-49\" # 自分で作ったモデル名に変更する\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "      \n",
        "    model = model_name,\n",
        "    prompt = test_prompt,\n",
        "    max_tokens = 500,\n",
        "    stop = [\"END\"],\n",
        "    )\n",
        "\n",
        "\n",
        "  answer= print(response['choices'][0]['text'])\n",
        "  \n",
        "    \n",
        "  return answer\n",
        "\n",
        "textbox = gr.Textbox(label=\"Type your query here:\", placeholder=\"Your Query\", lines=2)\n",
        "# \n",
        "gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\").launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}